{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers, optimizers, losses, models\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhaseLayer(layers.Layer):\n",
    "    def __init__(self, rng=np.random.RandomState(23456),units=512, input_dim=512, number_of_phases=4):\n",
    "        super(PhaseLayer, self).__init__()\n",
    "        self.nslices = number_of_phases\n",
    "        self.units = units\n",
    "        self.input_dim = input_dim\n",
    "        self.rng = rng\n",
    "    \n",
    "        self.w = tf.Variable(self.initial_alpha(), name=\"w\", trainable=True)\n",
    "        self.b = tf.Variable(self.initial_beta(), name=\"b\", trainable=True)\n",
    "    \n",
    "    def initial_alpha(self):\n",
    "        shape = (self.nslices, self.input_dim, self.units)\n",
    "        alpha_bound = np.sqrt(6. / np.prod(shape[-2:]))\n",
    "        alpha = np.asarray(\n",
    "            self.rng.uniform(low=-alpha_bound, high=alpha_bound, size=shape),\n",
    "            dtype=np.float32\n",
    "        )\n",
    "        return tf.convert_to_tensor(alpha, dtype=tf.float32)\n",
    "    \n",
    "    def initial_beta(self):\n",
    "        return tf.zeros((self.nslices, self.units), dtype=tf.float32)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PFNN(tf.keras.Model):\n",
    "    def __init__(self, input_dim=1, output_dim=1, dropout=0.3, **kwargs):\n",
    "        super(PFNN ,self).__init__(**kwargs)\n",
    "        self.nslices = 4\n",
    "        self.input_dim=input_dim\n",
    "        self.output_dim=output_dim\n",
    "    \n",
    "        self.dropout0 = layers.Dropout(dropout)\n",
    "        self.dropout1 = layers.Dropout(dropout)\n",
    "        self.dropout2 = layers.Dropout(dropout)\n",
    "    \n",
    "        self.activation = layers.ELU()\n",
    "    \n",
    "        self.layer0 = PhaseLayer(input_dim=input_dim)\n",
    "        self.layer1 = PhaseLayer()\n",
    "        self.layer2 = PhaseLayer(units=output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        pscale = self.nslices * inputs[:,-1]\n",
    "        pamount = pscale % 1.0\n",
    "    \n",
    "        pindex_1 = tf.cast(pscale, 'int32') % self.nslices\n",
    "        pindex_0 = (pindex_1-1) % self.nslices\n",
    "        pindex_2 = (pindex_1+1) % self.nslices\n",
    "        pindex_3 = (pindex_1+2) % self.nslices\n",
    "    \n",
    "        bamount = tf.expand_dims(pamount, 1)\n",
    "        wamount = tf.expand_dims(bamount, 1)\n",
    "\n",
    "        def cubic(y0, y1, y2, y3, mu):\n",
    "            return (\n",
    "           (-0.5*y0+1.5*y1-1.5*y2+0.5*y3)*mu*mu*mu + \n",
    "           (y0-2.5*y1+2.0*y2-0.5*y3)*mu*mu + \n",
    "           (-0.5*y0+0.5*y2)*mu +\n",
    "           (y1))\n",
    "    \n",
    "        W0 = cubic(\n",
    "            tf.nn.embedding_lookup(self.layer0.w, pindex_0), \n",
    "            tf.nn.embedding_lookup(self.layer0.w, pindex_1), \n",
    "            tf.nn.embedding_lookup(self.layer0.w, pindex_2), \n",
    "            tf.nn.embedding_lookup(self.layer0.w, pindex_3), \n",
    "            wamount)\n",
    "        W1 = cubic(\n",
    "            tf.nn.embedding_lookup(self.layer1.w, pindex_0), \n",
    "            tf.nn.embedding_lookup(self.layer1.w, pindex_1), \n",
    "            tf.nn.embedding_lookup(self.layer1.w, pindex_2), \n",
    "            tf.nn.embedding_lookup(self.layer1.w, pindex_3), \n",
    "            wamount)\n",
    "        W2 = cubic(\n",
    "            tf.nn.embedding_lookup(self.layer2.w, pindex_0), \n",
    "            tf.nn.embedding_lookup(self.layer2.w, pindex_1), \n",
    "            tf.nn.embedding_lookup(self.layer2.w, pindex_2), \n",
    "            tf.nn.embedding_lookup(self.layer2.w, pindex_3), \n",
    "            wamount)\n",
    "        \n",
    "        b0 = cubic(\n",
    "            tf.nn.embedding_lookup(self.layer0.b, pindex_0), \n",
    "            tf.nn.embedding_lookup(self.layer0.b, pindex_1), \n",
    "            tf.nn.embedding_lookup(self.layer0.b, pindex_2), \n",
    "            tf.nn.embedding_lookup(self.layer0.b, pindex_3), \n",
    "            bamount)\n",
    "        b1 = cubic(\n",
    "            tf.nn.embedding_lookup(self.layer1.b, pindex_0),\n",
    "            tf.nn.embedding_lookup(self.layer1.b, pindex_1),\n",
    "            tf.nn.embedding_lookup(self.layer1.b, pindex_2),\n",
    "            tf.nn.embedding_lookup(self.layer1.b, pindex_3),\n",
    "            bamount)\n",
    "        b2 = cubic(\n",
    "            tf.nn.embedding_lookup(self.layer2.b, pindex_0),\n",
    "            tf.nn.embedding_lookup(self.layer2.b, pindex_1),\n",
    "            tf.nn.embedding_lookup(self.layer2.b, pindex_2),\n",
    "            tf.nn.embedding_lookup(self.layer2.b, pindex_3),\n",
    "            bamount)\n",
    "        \n",
    "        H0 = inputs[:, :-1]\n",
    "        H1 = self.activation(tf.matmul(self.dropout0(H0), W0) + b0)\n",
    "        H2 = self.activation(tf.matmul(self.dropout0(H1), W1) + b1)\n",
    "        H3 = tf.matmul(self.dropout2(H2), W2) + b2\n",
    "    \n",
    "        return H3\n",
    "    \n",
    "    def save_checkpoint(self, direction):\n",
    "        W0 = self.layer0.w.numpy()\n",
    "        W1 = self.layer1.w.numpy()\n",
    "        W2 = self.layer2.w.numpy()\n",
    "        \n",
    "        b0 = self.layer0.b.numpy()\n",
    "        b1 = self.layer1.b.numpy()\n",
    "        b2 = self.layer2.b.numpy()\n",
    "        np.savez_compressed(direction + \"layer0\", weights=W0, bias=b0)\n",
    "        np.savez_compressed(direction + \"layer1\", weights=W1, bias=b1)\n",
    "        np.savez_compressed(direction + \"layer2\", weights=W0, bias=b2)\n",
    "    def load_checkpoint(self, direction):\n",
    "        layer0 = np.load(direction + \"layer0.npz\")\n",
    "        self.layer0.w = tf.Variable(layer0[\"weights\"], name=\"w\", trainable=True)\n",
    "        self.layer0.b = tf.Variable(layer0[\"bias\"], name=\"b\", trainable=True)\n",
    "        del layer0\n",
    "        layer1 = np.load(direction + \"layer1.npz\")\n",
    "        self.layer1.w = tf.Variable(layer1[\"weights\"], name=\"w\", trainable=True)\n",
    "        self.layer1.b = tf.Variable(layer1[\"bias\"], name=\"b\", trainable=True)\n",
    "        del layer1\n",
    "        layer2 = np.load(direction + \"layer2.npz\")\n",
    "        self.layer2.w = tf.Variable(layer2[\"weights\"], name=\"w\", trainable=True)\n",
    "        self.layer2.b = tf.Variable(layer2[\"bias\"], name=\"b\", trainable=True)\n",
    "        del layer2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfnn = PFNN(input_dim=342, output_dim=311)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(4, 342, 512) dtype=float32, numpy=\n",
      "array([[[ 3.9915387e-03, -2.2735364e-04, -5.3028404e-03, ...,\n",
      "         -4.9895314e-03, -4.4215922e-03, -2.0417425e-05],\n",
      "        [-5.5587054e-03, -1.8462978e-03,  3.2985634e-03, ...,\n",
      "         -4.4966852e-03, -3.3647593e-03,  4.7771307e-03],\n",
      "        [ 2.1949239e-04, -5.3447997e-03, -5.5682147e-03, ...,\n",
      "         -2.2389719e-03,  2.5809940e-03, -3.4271574e-03],\n",
      "        ...,\n",
      "        [-3.2437986e-03,  3.1618730e-04, -2.3515772e-03, ...,\n",
      "          1.1554204e-03,  8.1763515e-04, -1.5074635e-03],\n",
      "        [ 3.0957342e-03, -4.8389900e-03, -1.1360914e-03, ...,\n",
      "          3.1572573e-03, -3.4793492e-03, -2.8898085e-03],\n",
      "        [-2.7632623e-03,  4.5806213e-05,  3.8866622e-03, ...,\n",
      "         -2.5057618e-03,  4.4323169e-03,  5.7017626e-03]],\n",
      "\n",
      "       [[ 1.5719665e-03, -5.8694543e-05, -2.5987346e-03, ...,\n",
      "         -4.6469932e-03, -4.4354592e-03, -5.2308724e-03],\n",
      "        [-5.4492182e-03,  1.4326838e-03,  2.5002426e-03, ...,\n",
      "          4.2201784e-03, -1.5099817e-04,  4.7317008e-03],\n",
      "        [ 4.0371916e-03,  1.4900116e-03,  3.8464628e-03, ...,\n",
      "         -5.5508842e-03, -4.8352089e-03,  5.4638009e-03],\n",
      "        ...,\n",
      "        [-1.3986682e-03, -4.7517316e-03, -3.1506163e-03, ...,\n",
      "         -5.4389257e-03, -2.4243162e-03, -1.0207953e-03],\n",
      "        [ 2.3835110e-03, -1.7111134e-03,  1.3623488e-03, ...,\n",
      "         -1.8335242e-03, -1.4033607e-03,  4.8192833e-03],\n",
      "        [ 3.6898470e-03, -3.6458345e-03,  9.7941502e-04, ...,\n",
      "         -2.8203423e-03, -2.6110779e-03,  3.1854536e-03]],\n",
      "\n",
      "       [[-7.4860989e-04,  4.9401997e-03,  2.5336738e-04, ...,\n",
      "         -1.9035577e-03, -2.4283973e-03, -1.5244161e-03],\n",
      "        [ 1.7926417e-03, -5.4057222e-03, -2.6827168e-03, ...,\n",
      "          4.6928143e-03,  5.7039130e-04, -3.5039689e-03],\n",
      "        [ 3.4366711e-03, -2.5406950e-03, -3.1509057e-03, ...,\n",
      "         -4.4816015e-03, -4.2543067e-03,  3.2765772e-03],\n",
      "        ...,\n",
      "        [-2.4181299e-03,  2.6326964e-03,  5.0323219e-03, ...,\n",
      "          6.8054529e-04,  3.3794445e-04, -2.7714942e-03],\n",
      "        [ 4.8963944e-03, -4.5865811e-03,  2.1027606e-03, ...,\n",
      "          1.3429775e-03,  5.2714846e-03,  9.0194959e-04],\n",
      "        [ 2.7706577e-03,  2.4682344e-03, -2.5287555e-03, ...,\n",
      "          9.2642097e-04, -1.4040055e-03, -8.9651946e-04]],\n",
      "\n",
      "       [[ 4.1373600e-03, -3.3925364e-03, -5.5964147e-03, ...,\n",
      "         -3.9983569e-03, -1.4100561e-03, -3.9237058e-03],\n",
      "        [-5.4137795e-03,  2.3910415e-03, -5.1014395e-03, ...,\n",
      "          2.8550401e-03, -2.8129169e-03,  3.9779637e-03],\n",
      "        [ 6.1088393e-04, -1.1916677e-03, -6.4867741e-04, ...,\n",
      "         -2.3329013e-03,  4.2666956e-03, -5.3694570e-03],\n",
      "        ...,\n",
      "        [-1.9731603e-03,  9.9527196e-04, -5.1846649e-03, ...,\n",
      "         -4.2346353e-03,  3.9049052e-04, -3.0957959e-03],\n",
      "        [-1.6110243e-03, -1.0440849e-04, -1.4437316e-03, ...,\n",
      "         -3.3706808e-03, -4.6636979e-03, -4.1359919e-03],\n",
      "        [-5.4543023e-03,  9.1147015e-04, -1.5964155e-03, ...,\n",
      "          6.6984107e-04, -2.6206786e-03, -7.8376976e-04]]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(pfnn.layer0.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfnn.load_checkpoint(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'w:0' shape=(4, 342, 512) dtype=float32, numpy=\n",
      "array([[[-2.1874236e-02,  1.2708489e-02, -3.3418018e-02, ...,\n",
      "         -4.8815301e-03, -4.9065217e-02, -6.1113413e-02],\n",
      "        [-2.8227666e-02, -2.9756939e-03, -2.9001614e-02, ...,\n",
      "          3.3653039e-02, -1.5175923e-02, -8.6393934e-03],\n",
      "        [ 1.9796189e-02,  1.3329241e-02, -4.0740939e-03, ...,\n",
      "          1.5201372e-02, -1.0370106e-02, -1.5276201e-02],\n",
      "        ...,\n",
      "        [-7.6742661e-03,  1.4448602e-02,  3.0649295e-02, ...,\n",
      "          6.5858997e-02,  1.0008376e-02, -4.1618054e-03],\n",
      "        [-1.9641727e-02, -3.4242377e-02, -8.1533296e-03, ...,\n",
      "         -6.1956126e-02, -1.5728477e-02, -4.7052041e-02],\n",
      "        [ 3.1691357e-02, -2.0134596e-02,  3.2153707e-02, ...,\n",
      "         -4.4390369e-02,  2.7882820e-02,  7.0416592e-03]],\n",
      "\n",
      "       [[ 1.7522346e-02, -1.6397582e-02, -4.8347428e-03, ...,\n",
      "         -2.8847229e-02, -2.7360739e-02,  8.6625041e-03],\n",
      "        [ 1.2748019e-02,  2.2621073e-02, -7.5318590e-03, ...,\n",
      "          3.7453740e-03, -1.0143602e-02,  1.0319042e-02],\n",
      "        [-1.2628870e-02,  2.4127889e-02,  1.4670166e-03, ...,\n",
      "         -2.4166057e-02,  8.9866212e-03,  3.7938531e-03],\n",
      "        ...,\n",
      "        [-3.6099005e-02, -2.2370983e-02,  6.0623892e-02, ...,\n",
      "         -4.3578338e-02, -1.9293560e-02, -3.2502331e-02],\n",
      "        [-1.1900611e-02, -3.7258297e-02,  4.0084524e-03, ...,\n",
      "          6.3560847e-03,  5.2940929e-03,  4.0393420e-02],\n",
      "        [ 1.0409235e-02, -4.1459747e-02, -1.7989015e-02, ...,\n",
      "         -1.1245595e-02, -5.7579164e-04,  1.5463800e-02]],\n",
      "\n",
      "       [[ 4.5014326e-03, -6.7434865e-03, -1.9352080e-02, ...,\n",
      "         -1.5811964e-03, -4.6169087e-03, -6.7287022e-03],\n",
      "        [ 3.9797075e-02, -1.5229052e-02, -2.5875676e-02, ...,\n",
      "         -1.4975832e-02,  1.4432397e-02, -1.0386027e-02],\n",
      "        [ 2.8502418e-02, -1.6283998e-02, -2.3673221e-03, ...,\n",
      "          3.0392841e-03,  2.9817341e-02, -1.4945735e-03],\n",
      "        ...,\n",
      "        [-3.9609794e-02,  9.1266138e-03, -1.7412821e-02, ...,\n",
      "          1.7224319e-02, -1.8639027e-03,  1.5617281e-02],\n",
      "        [ 1.7530669e-02,  3.1110378e-02, -3.7425909e-02, ...,\n",
      "         -9.2834812e-03,  4.6662195e-03,  1.6729886e-02],\n",
      "        [ 2.3438774e-02, -9.8247016e-03, -6.3409465e-03, ...,\n",
      "         -5.0225421e-03,  1.0346659e-02,  1.9457895e-02]],\n",
      "\n",
      "       [[-1.0748462e-02,  5.5289599e-03,  6.0050469e-02, ...,\n",
      "          7.7003515e-03, -2.6393911e-02,  2.1249908e-03],\n",
      "        [-2.4298097e-03,  4.2527143e-02,  7.2187097e-03, ...,\n",
      "         -1.1412689e-03,  2.4288202e-05, -1.3221744e-02],\n",
      "        [-5.1147256e-02,  1.6610619e-02,  8.8859107e-03, ...,\n",
      "         -8.2113789e-03, -1.4905420e-02,  1.4049402e-02],\n",
      "        ...,\n",
      "        [ 1.9641167e-02,  3.1431898e-02, -3.4221284e-02, ...,\n",
      "         -1.2058038e-02, -1.9142992e-03, -2.3487809e-03],\n",
      "        [-7.8292387e-03,  5.7291504e-02,  1.2455940e-02, ...,\n",
      "         -3.1422619e-02,  1.5206066e-02,  3.6174040e-02],\n",
      "        [ 8.2572317e-03, -3.0261116e-02,  7.8561617e-04, ...,\n",
      "          2.8880225e-02,  2.1059141e-02, -3.0394347e-02]]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(pfnn.layer0.w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
